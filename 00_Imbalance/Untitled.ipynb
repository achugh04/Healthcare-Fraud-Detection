{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabebc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 10:50:17,803 : NumExpr defaulting to 8 threads.\n",
      "2021-12-07 10:50:35,291 : MWMOTE: Starting with 10794 instances\n",
      "2021-12-07 10:50:35,293 :  Step   0: Computing Knn table\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import math, bisect, random, logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s : %(message)s')\n",
    "\n",
    "class Knn:\n",
    "    \"\"\"docstring for Knn\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.dic = {}\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.data = data\n",
    "        self.real_indices = range(len(data))\n",
    "        for i in range(len(data)):\n",
    "            self.dic[(i, i)] = 0.\n",
    "            for j in range(i):\n",
    "                self.dic[(i, j)] = math.sqrt(math.fsum(((a - b) ** 2 for a, b in zip(self.data[i], self.data[j]))))\n",
    "                self.dic[(j, i)] = self.dic[(i, j)]\n",
    "\n",
    "    def fit_subset(self, indices):\n",
    "        self.real_indices = indices\n",
    "\n",
    "    def get_dis(self, a, b):\n",
    "        return self.dic[(a, b)]\n",
    "\n",
    "    def kneighbors(self, instance_index, n_neighbors, return_distance=False):\n",
    "        result = []\n",
    "        for i in self.real_indices:\n",
    "            distance = self.dic[(instance_index, i)]\n",
    "            result.append((distance, i))\n",
    "        result = sorted(result)[:n_neighbors]\n",
    "\n",
    "        if return_distance:\n",
    "            return ([i[1] for i in result], [i[0] for i in result])\n",
    "        else:\n",
    "            return [i[1] for i in result]\n",
    "\n",
    "class WeightedSampleRandomGenerator(object):\n",
    "    def __init__(self, indices, weights):\n",
    "        self.totals = []\n",
    "        # self.indices = indices\n",
    "        self.indices = list(indices)\n",
    "        running_total = 0\n",
    "\n",
    "        for w in weights:\n",
    "            running_total += w\n",
    "            self.totals.append(running_total)\n",
    "\n",
    "    def next(self):\n",
    "        rnd = random.random() * self.totals[-1]\n",
    "        b = bisect.bisect_right(self.totals, rnd)\n",
    "\n",
    "        i = self.indices[b]\n",
    "\n",
    "        return self.indices[bisect.bisect_right(self.totals, rnd)]\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.next()\n",
    "\n",
    "def clus_dis(A, B, K):\n",
    "    distance = 0.\n",
    "    for i in A:\n",
    "        for j in B:\n",
    "            distance += K.get_dis(i, j)\n",
    "    return distance / len(A) / len(B)\n",
    "\n",
    "def MWMOTE(X, Y, S_min, S_maj, N, k1=5, k2=3, k3=0.5, C_th=5, CMAX=2, C_p=3, return_mode='only'):\n",
    "    logger.debug('MWMOTE: Starting with %d instances' % len(Y))\n",
    "\n",
    "    '''\n",
    "    # Generating indices of S_min, S_maj\n",
    "    S_min, S_maj = [], []\n",
    "\n",
    "    #separate the S_min and S_maj\n",
    "    for index, i in enumerate(Y):\n",
    "        if i == 1:\n",
    "            S_min.append(index)\n",
    "        else:\n",
    "            S_maj.append(index)\n",
    "    '''\n",
    "    if type(k3) == float:\n",
    "        k3 = int(round(len(S_min) * k3))\n",
    "\n",
    "    k = Knn()\n",
    "\n",
    "    logger.debug(' Step   0: Computing Knn table')\n",
    "    k.fit(X)\n",
    "\n",
    "    # Step 1~2: Generating S_minf\n",
    "    S_minf = []\n",
    "    for i in S_min:\n",
    "        neighbors = k.kneighbors(i, k1 + 1)  # remove itself from neighbors\n",
    "        neighbors.remove(i)\n",
    "        if not all((neighbor in S_maj) for neighbor in neighbors):\n",
    "            S_minf.append(i)\n",
    "\n",
    "    logger.debug(' Step 1~2: %d in S_minf' % len(S_minf))\n",
    "\n",
    "    # Step 3~4: Generating S_bmaj\n",
    "    k.fit_subset(S_maj)\n",
    "    S_bmaj = []\n",
    "    for i in S_minf:\n",
    "        neighbors = k.kneighbors(i, k2)\n",
    "        S_bmaj.extend(neighbors)\n",
    "    S_bmaj = list(set(S_bmaj))\n",
    "    logger.debug(' Step 3~4: %d in S_bmaj' % len(S_bmaj))\n",
    "\n",
    "    # Step 5~6: Generating S_imin\n",
    "    k.fit_subset(S_min)\n",
    "    S_imin = []\n",
    "    N_min = {}\n",
    "    for i in S_bmaj:\n",
    "        neighbors = k.kneighbors(i, k3)\n",
    "        S_imin.extend(neighbors)\n",
    "        N_min[i] = neighbors\n",
    "    S_imin = list(set(S_imin))\n",
    "    logger.debug(' Step 5~6: %d in S_imin' % len(S_imin))\n",
    "\n",
    "    # Step 7~9: Generating I_w, S_w, S_p\n",
    "    I_w = {}\n",
    "    for y in S_bmaj:\n",
    "        sum_C_f = 0.\n",
    "        for x in S_imin:\n",
    "            # closeness_factor\n",
    "            if x not in N_min[y]:\n",
    "                closeness_factor = 0.\n",
    "            else:\n",
    "                distance_n = math.sqrt(math.fsum(((a - b) ** 2 for a, b in zip(X[x], X[y])))) / len(X[x])\n",
    "                if distance_n == 0:\n",
    "                    closeness_factor = min(C_th, 0) / C_th * CMAX\n",
    "                else:\n",
    "                    closeness_factor = min(C_th, (1 / distance_n)) / C_th * CMAX\n",
    "\n",
    "            I_w[(y, x)] = closeness_factor\n",
    "            sum_C_f += I_w[(y, x)]\n",
    "        for x in S_imin:\n",
    "            closeness_factor = I_w[(y, x)]\n",
    "            density_factor = closeness_factor / sum_C_f\n",
    "            I_w[(y, x)] = closeness_factor * density_factor\n",
    "\n",
    "    S_w = {}\n",
    "    for x in S_imin:\n",
    "        S_w[x] = math.fsum((I_w[(y, x)]) for y in S_bmaj)\n",
    "\n",
    "    S_p = {}  # actually useless\n",
    "    WeightSum = math.fsum(S_w.values())\n",
    "    for x in S_w:\n",
    "        S_p[x] = float(S_w[x]) / WeightSum\n",
    "    logger.debug(' Step 7~9: %d in I_w' % len(I_w))\n",
    "\n",
    "    # Step 10:Generating L, clusters of S_min\n",
    "    d_avg = 0.\n",
    "    for i in S_minf:\n",
    "        tmp = []\n",
    "        for j in S_minf:\n",
    "            if i == j:\n",
    "                continue\n",
    "            tmp.append(math.sqrt(math.fsum(((a - b) ** 2 for a, b in zip(X[i], X[j])))))\n",
    "        d_avg += min(tmp)\n",
    "        d_avg /= len(S_minf)\n",
    "        T_h = d_avg * C_p\n",
    "\n",
    "        L = {index: [i] for index, i in enumerate(S_min)}\n",
    "\n",
    "        clusters_number = list(range(len(S_min)))\n",
    "\n",
    "        dis_table = [[0 for i in clusters_number] for j in clusters_number]\n",
    "        for i in clusters_number:\n",
    "            for j in clusters_number:\n",
    "                dis_table[i][j] = clus_dis(L[i], L[j], k)\n",
    "        MAX = max(max(j) for j in dis_table)\n",
    "        for i in clusters_number:\n",
    "            dis_table[i][i] = MAX\n",
    "\n",
    "        for i in S_min:\n",
    "            MIN = min(min(j) for j in dis_table)\n",
    "            if MIN > T_h:\n",
    "                break\n",
    "            for j in clusters_number:\n",
    "                if MIN in dis_table[j]:\n",
    "                    b = dis_table[j].index(MIN)\n",
    "                    a = j\n",
    "                    break\n",
    "            L[a].extend(L[b])\n",
    "\n",
    "            del L[b]\n",
    "            clusters_number.remove(b)\n",
    "            for j in clusters_number:\n",
    "                tmp = clus_dis(L[a], L[j], k)\n",
    "                dis_table[a][j] = tmp\n",
    "                dis_table[j][a] = tmp\n",
    "            dis_table[a][a] = MAX\n",
    "            for j in clusters_number:\n",
    "                dis_table[b][j] = MAX\n",
    "                dis_table[j][b] = MAX\n",
    "\n",
    "        which_cluster = {}\n",
    "        for i, clu in L.items():\n",
    "            for j in clu:\n",
    "                which_cluster[j] = i\n",
    "        logger.debug(' Step  10: %d clusters' % len(L))\n",
    "\n",
    "        # Step 11: Generating X_gen, Y_gen\n",
    "        X_gen = []\n",
    "        some_big_number = 10000000.\n",
    "        sample = WeightedSampleRandomGenerator(S_w.keys(), S_w.values())\n",
    "        for z in range(N):\n",
    "            x = sample()\n",
    "            print(\"x:\", x)\n",
    "            index = (L[which_cluster[x]])\n",
    "            y = random.choice(index)\n",
    "            alpha = random.randint(0, some_big_number) / some_big_number\n",
    "            s = [i + alpha * (j - i) for i, j in zip(X[x], X[y])]\n",
    "            X_gen.append(s)\n",
    "        Y_gen = [1 for z in range(N)]\n",
    "        logger.debug(' Step  11: %d over-sample generated' % N)\n",
    "\n",
    "        # return the desired data\n",
    "        # X.extend(X_gen)\n",
    "        # Y.extend(Y_gen)\n",
    "        if return_mode == 'append':\n",
    "            return (X, Y)\n",
    "        elif return_mode == 'shuffled':\n",
    "            Permutation = range(len(X))\n",
    "            random.shuffle(Permutation)\n",
    "            X = [X[i] for i in Permutation]\n",
    "            Y = [Y[i] for i in Permutation]\n",
    "            return (X, Y)\n",
    "        elif return_mode == 'only':\n",
    "            return (X_gen, Y_gen)\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# X_ret,Y_ret = MWMOTE(car_features,car_label,15419,k1 = 5, k2 = 3, k3 = 0.5, C_th = 5, CMAX = 2, C_p = 3, return_mode = 'only')\n",
    "\n",
    "# divide the dataset into S_min and S_maj\n",
    "# Divide the data into fraudulent and non-fraudulent data\n",
    "# get the lable from the dataset\n",
    "\n",
    "# read the dataset\n",
    "Data = pd.read_csv('/Users/abhiishekchugh/Documents/GitHub/CANN-for-Fraud-Detection/Automobile Insurance/data/Pre-Processed_OneHotEncoding.csv')\n",
    "\n",
    "X = Data.iloc[:, :-1]\n",
    "y = Data.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# car_label = car_features['FraudFound']\n",
    "# drop the label\n",
    "# car_features.drop(['FraudFound'], inplace=True, axis=1)\n",
    "\n",
    "columnlable = list(X_train.columns.values)\n",
    "\n",
    "# create the dataframe for fraudulent and non-fraudulent data\n",
    "nonFraudulent = pd.DataFrame(columns=columnlable)\n",
    "nonFraudulentLable = pd.DataFrame(columns=['FraudFound'])\n",
    "\n",
    "fraudulent = pd.DataFrame(columns=columnlable)\n",
    "fraudulentLable = pd.DataFrame(columns=['FraudFound'])\n",
    "\n",
    "j = 0\n",
    "k = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if (y_train.iloc[i] == 0):\n",
    "        nonFraudulent.loc[j] = X_train.iloc[i]\n",
    "        nonFraudulentLable.loc[j] = 0\n",
    "        j += 1\n",
    "    else:\n",
    "        fraudulent.loc[k] = X_train.iloc[i]\n",
    "        fraudulentLable.loc[k] = 1\n",
    "        k += 1\n",
    "\n",
    "X = X_train.values\n",
    "Y = y_train.values\n",
    "S_min = fraudulent.values\n",
    "S_maj = nonFraudulent.values\n",
    "\n",
    "len(S_min)\n",
    "\n",
    "x_new, label_new = MWMOTE(X, Y, S_min, S_maj, 10793)\n",
    "\n",
    "# save the generated file.\n",
    "\n",
    "generatedNewData = pd.DataFrame(x_new)\n",
    "\n",
    "generatedNewData.shape\n",
    "\n",
    "generatedNewData.head()\n",
    "\n",
    "generatedNewData.to_csv(r'/Users/abhiishekchugh/Documents/GitHub/CANN-for-Fraud-Detection/Automobile Insurance/data/MWMOTE/mwmoteGeneratedOneHotData.csv', index=False)\n",
    "\n",
    "count = label_new.count(-1)\n",
    "\n",
    "print(count)\n",
    "\n",
    "newLabel = pd.DataFrame(label_new)\n",
    "\n",
    "newLabel.replace(-1, 1)\n",
    "\n",
    "newLabel.to_csv(r'/Users/abhiishekchugh/Documents/GitHub/CANN-for-Fraud-Detection/Automobile Insurance/data/MWMOTE/mwmoteGeneratedLabel.csv', index=False )\n",
    "\n",
    "X_test.to_csv(r\"/Users/abhiishekchugh/Documents/GitHub/CANN-for-Fraud-Detection/Automobile Insurance/data/MWMOTE/X_test.csv\", index=False)\n",
    "y_test.to_csv(r\"/Users/abhiishekchugh/Documents/GitHub/CANN-for-Fraud-Detection/Automobile Insurance/data/MWMOTE/y_test.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
